{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5103 on context None\n",
      "Preallocating 10867/11439 Mb (0.950000) on cuda\n",
      "Mapped name None to device cuda: Tesla K40c (0000:81:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/fisheries/sample/\"\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "\n",
    "# batch_size=100\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16 import Vgg16\n",
    "vgg = Vgg16()\n",
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 213 images belonging to 8 classes.\n",
      "Found 307 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', shuffle = False, batch_size=batch_size)\n",
    "train_batches = get_batches(path+'train', shuffle = False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 8 classes.\n",
      "Found 213 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(path+'train')\n",
    "val_data = get_data(path+'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path+'train_data.bc',train_data)\n",
    "save_array(model_path+'val_data.bc',val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_array(model_path+'train_data.bc')\n",
    "val_data = load_array(model_path+'val_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_classes = train_batches.classes\n",
    "train_labels = onehot(train_classes)\n",
    "val_classes = val_batches.classes\n",
    "val_labels = onehot(val_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = model.predict(train_data,batch_size=batch_size)\n",
    "val_features = model.predict(train_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path+'train_lastlayer_features.bc',train_features)\n",
    "save_array(model_path+'val_lastlayer_features.bc',val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = load_array(model_path+'train_lastlayer_features.bc')\n",
    "val_features = load_array(model_path+'val_lastlayer_features.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myModel = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 3, 224, 224)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myModel.add(BatchNormalization(axis=1,input_shape=(3,224,224)))\n",
    "myModel.add(Convolution2D(3,3,32,activation='relu'))\n",
    "myModel.add(BatchNormalization(axis=1))\n",
    "myModel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "myModel.add(Flatten())\n",
    "myModel.add(Dense(8,activation='softmax', W_regularizer=l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myModel.compile(sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "307/307 [==============================] - 12s - loss: 1.7846 - acc: 0.5765 - val_loss: 6.6033 - val_acc: 0.1831\n",
      "Epoch 2/2\n",
      "307/307 [==============================] - 11s - loss: 1.2089 - acc: 0.6743 - val_loss: 3.7177 - val_acc: 0.2113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe098831310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=2, \n",
    "                      validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major Key: SGD did way better than Adam on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myModel.optimizer.lr=1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "307/307 [==============================] - 11s - loss: 1.0734 - acc: 0.7199 - val_loss: 1.9440 - val_acc: 0.4883\n",
      "Epoch 2/2\n",
      "307/307 [==============================] - 11s - loss: 0.7735 - acc: 0.8274 - val_loss: 1.7796 - val_acc: 0.4883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe07510dfd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=2, \n",
    "                      validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increased lr by a factor of 10--went even better! 60.56% on validation but 97% on training... underfitting???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNorma (None, 3, 224, 224)   12          batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 3, 222, 193)   867         batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_2 (BatchNorma (None, 3, 222, 193)   12          convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 3, 111, 96)    0           batchnormalization_2[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 31968)         0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 8)             255752      flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 256,643\n",
      "Trainable params: 256,631\n",
      "Non-trainable params: 12\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "307/307 [==============================] - 11s - loss: 0.6615 - acc: 0.8697 - val_loss: 1.8520 - val_acc: 0.5634\n",
      "Epoch 2/2\n",
      "307/307 [==============================] - 11s - loss: 0.5587 - acc: 0.9055 - val_loss: 1.7588 - val_acc: 0.5775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe074249750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=2,\n",
    "                     validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some data augmentation! I'll also now try 10 epochs and see if things improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myModel = Sequential([\n",
    "    BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "    Convolution2D(3,3,32,activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(8,activation='softmax', W_regularizer=l2(0.01))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "newModel = Sequential([\n",
    "    BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "    Convolution2D(3,3,32,activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(8,activation='softmax', W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nadam1(batches):\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "        Convolution2D(3,3,32,activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(8,activation='softmax', W_regularizer=l2(0.01))\n",
    "    ])\n",
    "\n",
    "    model.compile(Nadam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nadam w slower rate, 5 epochs\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 2.5352 - acc: 0.3811 - val_loss: 2.7860 - val_acc: 0.4648\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 1.9833 - acc: 0.4919 - val_loss: 2.4024 - val_acc: 0.4695\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 1.6503 - acc: 0.5700 - val_loss: 2.1790 - val_acc: 0.4225\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 1.4354 - acc: 0.6384 - val_loss: 2.1610 - val_acc: 0.4930\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 1.3813 - acc: 0.6319 - val_loss: 2.0069 - val_acc: 0.5117\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 1.3305 - acc: 0.6645 - val_loss: 2.3662 - val_acc: 0.4742\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 1.1625 - acc: 0.7068 - val_loss: 1.8504 - val_acc: 0.5822\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 11s - loss: 0.9239 - acc: 0.7590 - val_loss: 1.9372 - val_acc: 0.5493\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 1.0125 - acc: 0.7459 - val_loss: 1.8556 - val_acc: 0.6150\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 0.8473 - acc: 0.7915 - val_loss: 1.9488 - val_acc: 0.5634\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 0.9930 - acc: 0.7362 - val_loss: 1.9149 - val_acc: 0.5728\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 0.8264 - acc: 0.7948 - val_loss: 1.8654 - val_acc: 0.5962\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 0.8495 - acc: 0.8078 - val_loss: 1.9818 - val_acc: 0.5822\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 0.7029 - acc: 0.8469 - val_loss: 1.7591 - val_acc: 0.6103\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 0.8047 - acc: 0.7948 - val_loss: 1.8144 - val_acc: 0.5869\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 0.8310 - acc: 0.7948 - val_loss: 2.2518 - val_acc: 0.5681\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 0.6199 - acc: 0.8534 - val_loss: 1.9282 - val_acc: 0.6103\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 10s - loss: 0.5734 - acc: 0.8697 - val_loss: 2.2699 - val_acc: 0.6103\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 0.6346 - acc: 0.8404 - val_loss: 2.0220 - val_acc: 0.6197\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 0.5734 - acc: 0.8958 - val_loss: 2.0441 - val_acc: 0.6197\n"
     ]
    }
   ],
   "source": [
    "# print(\"Nadam:\")\n",
    "# myModel.compile(Nadam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# myModel.fit_generator(batches, batches.nb_sample, nb_epoch=10, \n",
    "#                     validation_data=val_batches, nb_val_samples=val_batches.nb_sample)\n",
    "\n",
    "print(\"Nadam w slower rate, 5 epochs\")\n",
    "model = nadam1(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation with everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.05, \n",
    "                                shear_range=0.1, rotation_range=15, channel_shift_range=20)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 2.4586 - acc: 0.3876 - val_loss: 3.0396 - val_acc: 0.3427\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 2.1106 - acc: 0.4658 - val_loss: 2.1184 - val_acc: 0.4789\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 1.9526 - acc: 0.5081 - val_loss: 2.2154 - val_acc: 0.4695\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 1.9679 - acc: 0.5277 - val_loss: 2.2608 - val_acc: 0.4554\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 1.9388 - acc: 0.4853 - val_loss: 2.0875 - val_acc: 0.5023\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 1.9619 - acc: 0.5277 - val_loss: 2.2217 - val_acc: 0.5070\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 1.8347 - acc: 0.5537 - val_loss: 2.3904 - val_acc: 0.4930\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 11s - loss: 1.8023 - acc: 0.5635 - val_loss: 2.2147 - val_acc: 0.5258\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 1.8591 - acc: 0.5603 - val_loss: 2.2778 - val_acc: 0.5164\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 1.5403 - acc: 0.6059 - val_loss: 2.3472 - val_acc: 0.5164\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 1.6693 - acc: 0.5993 - val_loss: 2.5966 - val_acc: 0.5352\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 1.8011 - acc: 0.5765 - val_loss: 2.5407 - val_acc: 0.5117\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 1.5340 - acc: 0.5961 - val_loss: 2.6173 - val_acc: 0.5634\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 1.6147 - acc: 0.6059 - val_loss: 2.4969 - val_acc: 0.5258\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 1.5844 - acc: 0.5896 - val_loss: 2.5623 - val_acc: 0.4742\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 1.5849 - acc: 0.5961 - val_loss: 2.6317 - val_acc: 0.5305\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 1.5488 - acc: 0.5896 - val_loss: 2.6498 - val_acc: 0.5399\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 11s - loss: 1.5577 - acc: 0.5668 - val_loss: 2.4135 - val_acc: 0.5352\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 1.6690 - acc: 0.5961 - val_loss: 2.5189 - val_acc: 0.5211\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 1.4140 - acc: 0.6417 - val_loss: 2.7212 - val_acc: 0.5540\n"
     ]
    }
   ],
   "source": [
    "model = nadam1(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's getting better--let's try turning down lr and running more epochs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings:\n",
    "We keep getting better! Epoch 5 of Nadam w a slower rate seems to be best, but it looks like we're overfitting on the training data a little bit... Let's come back and see what we can do to reduce this overfitting. \n",
    "\n",
    "Also, for some reason when I take things out of functions it starts giving me errors. I can't use model.optimizer.lr when I have model as a function but when I take it out I get a host of other errors.\n",
    "\n",
    "I'm also getting some cases where as the epoch continues the accuracy gets worse... Also in this specific case my val_loss was the highest on the final epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 1.4011 - acc: 0.6678 - val_loss: 2.4876 - val_acc: 0.5540\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 1.4969 - acc: 0.6482 - val_loss: 2.3973 - val_acc: 0.5634\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 1.5251 - acc: 0.6254 - val_loss: 2.6143 - val_acc: 0.4977\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 1.4222 - acc: 0.6124 - val_loss: 2.5558 - val_acc: 0.5587\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 1.6291 - acc: 0.6059 - val_loss: 2.6840 - val_acc: 0.5446\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 1.5204 - acc: 0.6319 - val_loss: 2.4550 - val_acc: 0.5352\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 1.3750 - acc: 0.6384 - val_loss: 2.2908 - val_acc: 0.5681\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 11s - loss: 1.3818 - acc: 0.6710 - val_loss: 2.6775 - val_acc: 0.5915\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 1.5074 - acc: 0.6450 - val_loss: 2.6073 - val_acc: 0.5258\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 1.7378 - acc: 0.5896 - val_loss: 2.2587 - val_acc: 0.6056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe065368dd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I know:\n",
    "We're most likely underfitting--val accuracy/loss gets worse as time goes on sometimes, it doesn't seem like there's a consistent improvement or decline though. I've added both data aug and L2 regularization, so I'm not sure what other ways might help with what I'm trying to do. Maybe remove L2 since it technically prevents ~overfitting?\n",
    "\n",
    "Let's also try less data aug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 307 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.05, \n",
    "                                shear_range=0.1, channel_shift_range=20)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 1.1075 - acc: 0.6906 - val_loss: 2.3134 - val_acc: 0.5822\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 1.3541 - acc: 0.6710 - val_loss: 2.5433 - val_acc: 0.5164\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 1.3007 - acc: 0.6580 - val_loss: 2.4596 - val_acc: 0.5775\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 1.3090 - acc: 0.6580 - val_loss: 2.5375 - val_acc: 0.5634\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 1.2172 - acc: 0.6775 - val_loss: 2.4922 - val_acc: 0.5493\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 1.1170 - acc: 0.6971 - val_loss: 2.5441 - val_acc: 0.5540\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 1.3022 - acc: 0.6678 - val_loss: 2.6452 - val_acc: 0.5587\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 11s - loss: 1.1414 - acc: 0.7231 - val_loss: 2.6676 - val_acc: 0.5728\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 1.1406 - acc: 0.7003 - val_loss: 2.4358 - val_acc: 0.5587\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 1.1764 - acc: 0.7134 - val_loss: 2.6273 - val_acc: 0.5634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe065368f50>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nadam2(batches):\n",
    "    #same as before, just without L2!\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "        Convolution2D(3,3,32,activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        Dense(8,activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(Nadam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 2.2928 - acc: 0.3909 - val_loss: 2.5572 - val_acc: 0.4413\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 1.9985 - acc: 0.4756 - val_loss: 2.1686 - val_acc: 0.3709\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 1.5476 - acc: 0.5700 - val_loss: 2.1391 - val_acc: 0.4460\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 1.8373 - acc: 0.4886 - val_loss: 2.7411 - val_acc: 0.3709\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 1.6762 - acc: 0.5570 - val_loss: 2.3732 - val_acc: 0.4789\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 1.5732 - acc: 0.6091 - val_loss: 2.1126 - val_acc: 0.5728\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 1.2451 - acc: 0.6515 - val_loss: 2.2953 - val_acc: 0.5070\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 11s - loss: 1.6839 - acc: 0.5961 - val_loss: 2.3208 - val_acc: 0.4836\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 1.4500 - acc: 0.6352 - val_loss: 2.2735 - val_acc: 0.4695\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 1.3605 - acc: 0.6319 - val_loss: 2.1790 - val_acc: 0.4930\n",
      "Epoch 1/10\n",
      "307/307 [==============================] - 12s - loss: 1.3481 - acc: 0.6384 - val_loss: 2.0906 - val_acc: 0.5634\n",
      "Epoch 2/10\n",
      "307/307 [==============================] - 11s - loss: 1.2524 - acc: 0.6840 - val_loss: 2.2438 - val_acc: 0.5164\n",
      "Epoch 3/10\n",
      "307/307 [==============================] - 11s - loss: 1.2339 - acc: 0.6515 - val_loss: 2.3701 - val_acc: 0.5258\n",
      "Epoch 4/10\n",
      "307/307 [==============================] - 11s - loss: 1.2960 - acc: 0.6221 - val_loss: 2.1161 - val_acc: 0.5446\n",
      "Epoch 5/10\n",
      "307/307 [==============================] - 11s - loss: 1.3181 - acc: 0.6352 - val_loss: 2.1475 - val_acc: 0.5493\n",
      "Epoch 6/10\n",
      "307/307 [==============================] - 11s - loss: 1.3639 - acc: 0.6287 - val_loss: 2.3719 - val_acc: 0.4554\n",
      "Epoch 7/10\n",
      "307/307 [==============================] - 11s - loss: 1.1513 - acc: 0.6612 - val_loss: 2.3568 - val_acc: 0.5070\n",
      "Epoch 8/10\n",
      "307/307 [==============================] - 11s - loss: 1.1248 - acc: 0.6515 - val_loss: 2.3735 - val_acc: 0.4742\n",
      "Epoch 9/10\n",
      "307/307 [==============================] - 11s - loss: 0.9928 - acc: 0.7362 - val_loss: 2.3203 - val_acc: 0.5540\n",
      "Epoch 10/10\n",
      "307/307 [==============================] - 11s - loss: 1.1045 - acc: 0.6808 - val_loss: 2.2094 - val_acc: 0.5446\n"
     ]
    }
   ],
   "source": [
    "model2 = nadam2(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Simple Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "        Flatten(),\n",
    "        Dense(8,activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "307/307 [==============================] - 13s - loss: 9.2871 - acc: 0.4007 - val_loss: 8.7779 - val_acc: 0.4554\n",
      "Epoch 2/3\n",
      "307/307 [==============================] - 11s - loss: 8.3692 - acc: 0.4756 - val_loss: 9.6039 - val_acc: 0.3991\n",
      "Epoch 3/3\n",
      "307/307 [==============================] - 12s - loss: 8.0328 - acc: 0.5016 - val_loss: 9.5357 - val_acc: 0.4085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee6f9cd1d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, train_batches.nb_sample,nb_epoch=3, validation_data = val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNorma (None, 3, 224, 224)   12          batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 150528)        0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 8)             1204232     flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,204,244\n",
      "Trainable params: 1,204,238\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'N'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-23cb4860a92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'N'"
     ]
    }
   ],
   "source": [
    "np.round(model.predict_generator(train_batches, train_batches.N)[:10],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a lower learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "307/307 [==============================] - 12s - loss: 8.0328 - acc: 0.5016 - val_loss: 9.5571 - val_acc: 0.4038\n",
      "Epoch 2/3\n",
      "307/307 [==============================] - 11s - loss: 8.0328 - acc: 0.5016 - val_loss: 9.5918 - val_acc: 0.4038\n",
      "Epoch 3/3\n",
      "307/307 [==============================] - 11s - loss: 8.0328 - acc: 0.5016 - val_loss: 9.5874 - val_acc: 0.4038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee4cafb190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh, val_acc = 0.4038 for every one of the above--that's interesting consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "307/307 [==============================] - 12s - loss: 8.0328 - acc: 0.5016 - val_loss: 9.5942 - val_acc: 0.3991\n",
      "Epoch 2/3\n",
      "307/307 [==============================] - 11s - loss: 8.0328 - acc: 0.5016 - val_loss: 9.6017 - val_acc: 0.3991\n",
      "Epoch 3/3\n",
      "307/307 [==============================] - 12s - loss: 8.0328 - acc: 0.5016 - val_loss: 9.6053 - val_acc: 0.3991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee4c8f4110>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, acc=0.5016 the same as before, while val_acc is lower but only slightly so at 0.3991--but they're all the same again!! So we've hit some sort of consistency but we're still probably at either some local minimum or jumping too far to hit the global?S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 213 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "rnd_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.61,  0.4 ],\n",
       "       [ 9.23,  0.42],\n",
       "       [ 9.45,  0.41],\n",
       "       [ 9.91,  0.38],\n",
       "       [ 9.91,  0.38],\n",
       "       [ 9.76,  0.39],\n",
       "       [ 9.53,  0.4 ],\n",
       "       [ 9.45,  0.41],\n",
       "       [ 9.83,  0.38],\n",
       "       [ 9.53,  0.4 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_res = [model.evaluate_generator(rnd_batches, rnd_batches.nb_sample) for i in range(10)]\n",
    "np.round(val_res,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From StackOverflow: evaluate_generator uses both your test input and output. It first predicts output using training input and then evaluates performance by comparing it against your test output. So it gives out a measure of performance, i.e. accuracy in your case.\n",
    "\n",
    "So what we just did above was see what the performance of our model is on 10 things so we can see if there are statstically significant differences in performance. \n",
    "\n",
    "Turns out it's pretty consistent:\n",
    "\n",
    "min_acc = 0.38\n",
    "max_acc = 0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear w/ L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "307/307 [==============================] - 13s - loss: 11.0260 - acc: 0.1889 - val_loss: 12.8843 - val_acc: 0.1784\n",
      "Epoch 2/3\n",
      "307/307 [==============================] - 11s - loss: 9.8730 - acc: 0.3453 - val_loss: 12.3482 - val_acc: 0.1737\n",
      "Epoch 3/3\n",
      "307/307 [==============================] - 11s - loss: 7.8282 - acc: 0.4788 - val_loss: 9.7379 - val_acc: 0.3709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee4c7b2b50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "        Flatten(),\n",
    "        Dense(8,activation='softmax', W_regularizer=l2(0.01))\n",
    "    ])\n",
    "\n",
    "model.compile(Adam(lr=10e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that got... worse? Except for the last val_acc=.3709 which seems close to what we had before but now val_acc is around .17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "307/307 [==============================] - 12s - loss: 6.9488 - acc: 0.5537 - val_loss: 8.8606 - val_acc: 0.4085\n",
      "Epoch 2/3\n",
      "307/307 [==============================] - 11s - loss: 6.4381 - acc: 0.5798 - val_loss: 7.6627 - val_acc: 0.5023\n",
      "Epoch 3/3\n",
      "307/307 [==============================] - 13s - loss: 5.8013 - acc: 0.6287 - val_loss: 7.6443 - val_acc: 0.5258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee4c8e7e90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "woahhhh we jumped like 10 whole percents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "307/307 [==============================] - 12s - loss: 2.4102 - acc: 0.1107 - val_loss: 5.9550 - val_acc: 0.0516\n",
      "Epoch 2/3\n",
      "307/307 [==============================] - 11s - loss: 2.2192 - acc: 0.1433 - val_loss: 3.3458 - val_acc: 0.0704\n",
      "Epoch 3/3\n",
      "307/307 [==============================] - 11s - loss: 2.1259 - acc: 0.1759 - val_loss: 2.7295 - val_acc: 0.0939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee6ee577d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(8,activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our models on the full dataset to see wtf happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#redefine location:\n",
    "path = \"data/fisheries/\"\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 756 images belonging to 8 classes.\n",
      "Found 3021 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', shuffle = False, batch_size=batch_size)\n",
    "train_batches = get_batches(path+'train', shuffle = False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3021 images belonging to 8 classes.\n",
      "Found 756 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(path+'train')\n",
    "val_data = get_data(path+'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path+'train_data.bc',train_data)\n",
    "save_array(model_path+'val_data.bc',val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_array(model_path+'train_data.bc')\n",
    "val_data = load_array(model_path+'val_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_classes = train_batches.classes\n",
    "train_labels = onehot(train_classes)\n",
    "val_classes = val_batches.classes\n",
    "val_labels = onehot(val_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3021/3021 [==============================] - 113s - loss: 2.3006 - acc: 0.1026 - val_loss: 6.8776 - val_acc: 0.1085\n",
      "Epoch 2/5\n",
      "3021/3021 [==============================] - 90s - loss: 2.1338 - acc: 0.1387 - val_loss: 4.0829 - val_acc: 0.0979\n",
      "Epoch 3/5\n",
      "3021/3021 [==============================] - 80s - loss: 2.0865 - acc: 0.1625 - val_loss: 2.4723 - val_acc: 0.1362\n",
      "Epoch 4/5\n",
      "3021/3021 [==============================] - 76s - loss: 2.0624 - acc: 0.1801 - val_loss: 2.1891 - val_acc: 0.1772\n",
      "Epoch 5/5\n",
      "3021/3021 [==============================] - 77s - loss: 2.0405 - acc: 0.1993 - val_loss: 1.9989 - val_acc: 0.2235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f111fed5210>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(8,activation='softmax')\n",
    "    ])\n",
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=5, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3021/3021 [==============================] - 88s - loss: 2.0324 - acc: 0.2171 - val_loss: 1.9101 - val_acc: 0.2540\n",
      "Epoch 2/5\n",
      "3021/3021 [==============================] - 74s - loss: 2.0216 - acc: 0.2122 - val_loss: 1.8664 - val_acc: 0.2844\n",
      "Epoch 3/5\n",
      "3021/3021 [==============================] - 73s - loss: 2.0090 - acc: 0.2105 - val_loss: 1.8136 - val_acc: 0.3280\n",
      "Epoch 4/5\n",
      "3021/3021 [==============================] - 74s - loss: 1.9979 - acc: 0.2387 - val_loss: 1.7976 - val_acc: 0.3836\n",
      "Epoch 5/5\n",
      "3021/3021 [==============================] - 74s - loss: 1.9893 - acc: 0.2483 - val_loss: 1.7904 - val_acc: 0.3730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11247af7d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.001\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=5, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a different batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 756 images belonging to 8 classes.\n",
      "Found 3021 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', shuffle = False, batch_size=batch_size)\n",
    "train_batches = get_batches(path+'train', shuffle = False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok we need to actually do smth w batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 756 images belonging to 8 classes.\n",
      "Found 3021 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', shuffle = False, batch_size=batch_size)\n",
    "train_batches = get_batches(path+'train', shuffle = False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 86s - loss: 2.0613 - acc: 0.1837 - val_loss: 1.7948 - val_acc: 0.3611\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 79s - loss: 2.0496 - acc: 0.1870 - val_loss: 1.7940 - val_acc: 0.3505\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 78s - loss: 2.0377 - acc: 0.1903 - val_loss: 1.8203 - val_acc: 0.3148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11247af910>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr=0.001\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3021 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.05, \n",
    "                                shear_range=0.1, rotation_range=15, channel_shift_range=20)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 86s - loss: 1.7179 - acc: 0.4406 - val_loss: 1.2769 - val_acc: 0.6389\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 81s - loss: 1.4685 - acc: 0.5425 - val_loss: 1.1220 - val_acc: 0.6786\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 83s - loss: 1.3954 - acc: 0.5746 - val_loss: 1.0174 - val_acc: 0.7196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1114bc0590>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 86s - loss: 1.3066 - acc: 0.6001 - val_loss: 0.9981 - val_acc: 0.7050\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 79s - loss: 1.3039 - acc: 0.5995 - val_loss: 1.0082 - val_acc: 0.7183\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 78s - loss: 1.2326 - acc: 0.6379 - val_loss: 0.8996 - val_acc: 0.7474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1114881850>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try yet another batch size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 756 images belonging to 8 classes.\n",
      "Found 3021 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=4\n",
    "val_batches = get_batches(path+'valid', shuffle = False, batch_size=batch_size)\n",
    "train_batches = get_batches(path+'train', shuffle = False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3021 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.05, \n",
    "                                shear_range=0.1, rotation_range=15, channel_shift_range=20)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 84s - loss: 1.7100 - acc: 0.4472 - val_loss: 1.2677 - val_acc: 0.6257\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 87s - loss: 1.6613 - acc: 0.4489 - val_loss: 1.1852 - val_acc: 0.6706\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 84s - loss: 1.6243 - acc: 0.4641 - val_loss: 1.2041 - val_acc: 0.6429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1114881b90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 87s - loss: 1.5894 - acc: 0.4869 - val_loss: 1.1775 - val_acc: 0.6429\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 91s - loss: 1.5771 - acc: 0.4796 - val_loss: 1.2394 - val_acc: 0.6336\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 85s - loss: 1.5593 - acc: 0.4856 - val_loss: 1.1184 - val_acc: 0.6521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1114881d90>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Conv Layers, No Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "    Convolution2D(32,3,3,activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Convolution2D(64,3,3,activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Flatten(),\n",
    "    Dense(8,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 85s - loss: 5.7406 - acc: 0.6319 - val_loss: 11.6924 - val_acc: 0.2407\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 84s - loss: 9.2482 - acc: 0.4035 - val_loss: 12.6926 - val_acc: 0.2050\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 84s - loss: 7.7163 - acc: 0.4975 - val_loss: 8.3025 - val_acc: 0.4153\n",
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 84s - loss: 6.3223 - acc: 0.5885 - val_loss: 10.1639 - val_acc: 0.3280\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 83s - loss: 5.3827 - acc: 0.6485 - val_loss: 9.4309 - val_acc: 0.3545\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 83s - loss: 5.6896 - acc: 0.6236 - val_loss: 11.1571 - val_acc: 0.2632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f111462e090>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)\n",
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with augmented data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 87s - loss: 6.5129 - acc: 0.5081 - val_loss: 4.5715 - val_acc: 0.6548\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 86s - loss: 4.8140 - acc: 0.5770 - val_loss: 4.6160 - val_acc: 0.5979\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 84s - loss: 4.3397 - acc: 0.6071 - val_loss: 3.0918 - val_acc: 0.7063\n",
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 85s - loss: 3.8087 - acc: 0.6200 - val_loss: 3.2387 - val_acc: 0.7011\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 85s - loss: 3.3493 - acc: 0.6352 - val_loss: 2.8213 - val_acc: 0.7143\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 84s - loss: 2.9250 - acc: 0.6614 - val_loss: 2.1025 - val_acc: 0.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10e2adc150>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)\n",
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford-Recommended Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "    Convolution2D(32,3,3,activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Convolution2D(64,3,3,activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    BatchNormalization(axis=1),\n",
    "    Dense(8,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3021/3021 [==============================] - 85s - loss: 2.2835 - acc: 0.1278 - val_loss: 2.4026 - val_acc: 0.1680\n",
      "Epoch 2/5\n",
      "3021/3021 [==============================] - 84s - loss: 2.1379 - acc: 0.1235 - val_loss: 2.4434 - val_acc: 0.1627\n",
      "Epoch 3/5\n",
      "3021/3021 [==============================] - 84s - loss: 2.0888 - acc: 0.1599 - val_loss: 2.4579 - val_acc: 0.1481\n",
      "Epoch 4/5\n",
      "3021/3021 [==============================] - 84s - loss: 2.0530 - acc: 0.1887 - val_loss: 2.4119 - val_acc: 0.1680\n",
      "Epoch 5/5\n",
      "3021/3021 [==============================] - 84s - loss: 2.0260 - acc: 0.2099 - val_loss: 2.2868 - val_acc: 0.1892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10e29a2d10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(train_batches, train_batches.nb_sample, nb_epoch=5, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3021/3021 [==============================] - 86s - loss: 1.7861 - acc: 0.3853 - val_loss: 1.7726 - val_acc: 0.4683\n",
      "Epoch 2/3\n",
      "3021/3021 [==============================] - 85s - loss: 1.6163 - acc: 0.4657 - val_loss: 1.4920 - val_acc: 0.5251\n",
      "Epoch 3/3\n",
      "3021/3021 [==============================] - 85s - loss: 1.5182 - acc: 0.5197 - val_loss: 1.7912 - val_acc: 0.5860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f10e2a1d490>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=3, validation_data=val_batches,\n",
    "                   nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First... Let's grab ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "#gets last convolutional layer in the model so we can grab its output shape\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make a bn model with a simplified version of vgg dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128,activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(8,activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create features from vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3021 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=64, shuffle=False)\n",
    "#test_batches = get_batches(path+'test_stg1', shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3021 images belonging to 8 classes.\n",
      "Found 756 images belonging to 8 classes.\n",
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dbashir/anaconda2/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dbashir/anaconda2/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/engine/training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "  File \"/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.py\", line 832, in next\n",
      "    target_size=self.target_size)\n",
      "  File \"/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.py\", line 296, in load_img\n",
      "    img = pil_image.open(path)\n",
      "  File \"/home/dbashir/anaconda2/lib/python2.7/site-packages/PIL/Image.py\", line 2477, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "IOError: [Errno 2] No such file or directory: 'data/fisheries/test_stg1/unknown/img_04268.jpg'\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Error when checking : data should be a Numpy array, or list/dict of Numpy arrays. Found: None...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-adbe76e55b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconv_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconv_val_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconv_test_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                                             \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                                             \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m                                             pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \"\"\"\n\u001b[1;32m   1370\u001b[0m         x = standardize_input_data(x, self.input_names,\n\u001b[0;32m-> 1371\u001b[0;31m                                    self.internal_input_shapes)\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     83\u001b[0m                             \u001b[0;34m': data should be a Numpy array, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                             \u001b[0;34m'or list/dict of Numpy arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                             'Found: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# case: model expects multiple inputs but only received\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Error when checking : data should be a Numpy array, or list/dict of Numpy arrays. Found: None..."
     ]
    }
   ],
   "source": [
    "conv_feat = conv_model.predict_generator(batches,batches.nb_sample)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches,val_batches.nb_sample)\n",
    "conv_test_feat = conv_model.predict_generator(test_batches,test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array(path+'results/conv_test_feat.dat', conv_test_feat)\n",
    "save_array(path+'results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model=Sequential(get_bn_da_layers(p))\n",
    "bn_model.compile(Adam(lr=1e-5), loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data aug\n",
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "da_batches = get_batches(path+'train', gen_t, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = conv_model.predict_generator(da_batches,da_batches.nb_sample*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/da_conv_feat2.dat', da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = load_array(path+'results/da_conv_feat2.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = np.concatenate([da_conv_feat, conv_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for pseudo labeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pseudo = bn_model.predict(conv_val_feat,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_pseudo = np.concatenate([da_trn_labels,val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([da_conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune the model up we'll need to train the conv thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to load the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(path+'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size,nb_epoch=1,\n",
    "            validation_data=(conv_val_feat,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/bn-ps8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.metrics.categorical_crossentropy(val_labels, do_clip(val_preds, 0.93)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(path+'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path+'results/subm.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [a[4:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
