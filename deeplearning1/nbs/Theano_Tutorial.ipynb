{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5103 on context None\n",
      "Preallocating 10867/11439 Mb (0.950000) on cuda\n",
      "Mapped name None to device cuda: Tesla K40c (0000:81:00.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import theano.tensor as T\n",
    "from theano import function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics: Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.dscalar('x') #dscalar is 0 dimensional arrays (scalar) of doubles\n",
    "y = T.dscalar('y')\n",
    "z = x + y\n",
    "f = function([x,y],z) #f outputs a numpy ndarray w/ 0 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.allclose(f(16.3,12.1),28.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x + y)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#z just a var, can use pp (pretty print)\n",
    "from theano import pp\n",
    "pp(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add two matrices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = T.dmatrix('x') #dmatrix is the type for matrices of doubles\n",
    "y = T.dmatrix('y')\n",
    "z = x+y\n",
    "f = function([x,y],z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  22.],\n",
       "       [ 33.,  44.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([[1,2],[3,4]],[[10,20],[30,40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  22.],\n",
       "       [ 33.,  44.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can also use numpy arrays directly as inputs\n",
    "a = numpy.array([[1,2],[3,4]])\n",
    "b = numpy.array([[10,20],[30,40]])\n",
    "f(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: The code below is intended to compute $ a^2 + b^2 + 2 \\cdot a \\cdot b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.,  49.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.vector()\n",
    "b = T.vector()\n",
    "out = a**2 + b**2 + 2*a*b\n",
    "f = function([a,b],out)\n",
    "f([1,2],[4,5]) #will print out [25,49] since 1+4=5 and 2+5=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First will be the logistic function (sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.73105858],\n",
       "       [ 0.26894142,  0.11920292]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dmatrix('x')\n",
    "s = 1 / (1 + T.exp(-x))\n",
    "logistic = function([x],s)\n",
    "logistic([[0,1],[-1,-2]]) #will output another 2x2 matrix where we've computed the sigmoid of each of the entries elemntwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now verify the following equation: $$ s(x) = \\frac{1}{1 + e^{-x}} = \\frac{1 + \\tanh(x/2)}{2}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5       ,  0.73105858],\n",
       "       [ 0.26894142,  0.11920292]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = (1 + T.tanh(x/2))/2\n",
    "logistic2 = function([x],s2)\n",
    "logistic2([[0,1],[-1,-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing multiple things at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a,b = T.dmatrices('a','b')\n",
    "diff = a - b\n",
    "abs_diff = abs(diff)\n",
    "diff_squared = diff**2\n",
    "f = function([a,b],[diff,abs_diff,diff_squared])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  0.],\n",
       "        [-1., -2.]]), array([[ 1.,  0.],\n",
       "        [ 1.,  2.]]), array([[ 1.,  0.],\n",
       "        [ 1.,  4.]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f([[1,1],[1,1]],[[0,1],[2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting default argument value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. if we have a function that takes two numbers and we want an automatic value for one of them if we only give it one function as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(34.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import In\n",
    "x,y = T.dscalars('x','y')\n",
    "z = x + y\n",
    "f = function([x, In(y, value=1)], z) #the In class lets us create an instance where we can make y's default value 1.\n",
    "f(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(40.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(33,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import shared\n",
    "state = shared(0)\n",
    "inc = T.iscalar('inc')\n",
    "accumulator = function([inc],state,updates=[(state,state+inc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New things:\n",
    "The shared thing above constructs shared variables--they have a value that can be shared between functions. They can be used in symbolic expressions, but also have an internal value that defines the value taken on by the symbol in $all$ functions that use it. We can access and modify that value using .get_value() and .set_value()\n",
    "\n",
    "The updates parameter of the function. We must supply it with a list of pairs of the form (shared_variable, new expression). Each time it runs, it will replace the .value of the shared variable with the new expression. Above, we replace the state's value with the value of state plus the increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "301\n"
     ]
    }
   ],
   "source": [
    "print(state.get_value())\n",
    "accumulator(1)\n",
    "print(state.get_value())\n",
    "accumulator(300)\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "state.set_value(-1)\n",
    "accumulator(3)\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll define another function that can also update the value of the shared variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "decrementor = function([inc],state,updates=[(state,state-inc)])\n",
    "decrementor(2)\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to express a formula using the shared variable but do $not$ want to use its value, we can use the givens parameter of the function to replace a node in a graph for the purpose of a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "fn_of_state = state*2 + inc\n",
    "#this type of foo has to match state, which we replace w/ givens\n",
    "foo = T.scalar(dtype=state.dtype)\n",
    "skip_shared = function([inc,foo], fn_of_state, givens=[(state,foo)])\n",
    "skip_shared(1,3) #we're using 3 as the value of state in this function, but NOT as state.value\n",
    "\n",
    "print(state.get_value()) #this should still be 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "accumulator(10)\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a copy to create a similar accumulator with its own internal state using the swap parameter, a dictionary of shared variables to exchange. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "new_state = shared(0)\n",
    "new_accumulator = accumulator.copy(swap={state:new_state})\n",
    "new_accumulator(100)\n",
    "#this should now accumulate new_state, and act just as the original accumulator did!\n",
    "print(new_state.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(state.get_value()) #this should be left the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we'll create a copy with updates removed\n",
    "null_accumulator = accumulator.copy(delete_updates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "null_accumulator(9000)\n",
    "print(state.get_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "srng = RandomStreams(seed=234)\n",
    "rv_u = srng.uniform((2,2)) #random stream of 2x2 matrices drawn from a uniform distribution\n",
    "rv_n = srng.normal((2,2))\n",
    "f = function([],rv_u) #calling f() gives random uniform numbers\n",
    "g = function([],rv_n,no_default_updates=True) #no_default_updates means if we call g multiple times get same numbers\n",
    "nearly_zeros = function([],rv_u+rv_u - 2*rv_u) # a random var drawn at most once during function execution, so\n",
    "# this will return approx 0 even though rv_u drawn thrice in the fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_val0 = f()\n",
    "f_val1 = f() #different numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_val0 = g()\n",
    "g_val1 = g() #the same numbers as above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeding streams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng_val = rv_u.rng.get_value(borrow=True) #get rng val for rv_u\n",
    "rng_val.seed(89234) #seed the generator\n",
    "rv_u.rng.set_value(rng_val,borrow=True) #assign back seeded rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#can seed all vars allocated by RandomStreams object\n",
    "srng.seed(902340)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharing streams between functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_after_v0 = rv_u.rng.get_value().get_state()\n",
    "nearly_zeros()\n",
    "\n",
    "v1 = f()\n",
    "rng = rv_u.rng.get_value(borrow=True)\n",
    "rng.set_state(state_after_v0)\n",
    "rv_u.rng.set_value(rng,borrow=True)\n",
    "v2 = f() #v2 != v1\n",
    "v3 = f() #v3 == v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Graph():\n",
    "    def __init__(self,seed=123):\n",
    "        self.rng = RandomStreams(seed)\n",
    "        self.y = self.rng.uniform(size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = Graph(seed=123)\n",
    "f1 = function([],g1.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g2 = Graph(seed=987)\n",
    "f2 = function([],g2.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.59044123], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55421311], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_random_state(g1,g2):\n",
    "    if isinstance(g1.rng, MRG_RandomStreams):\n",
    "        g2.rng.rstate = g1.rng.rstate\n",
    "        \n",
    "    for(su1,su2) in zip(g1.rng.state_updates,g2.rng.state_updates):\n",
    "        su2[0].set_value(su1[0].get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23715077], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_random_state(g1,g2) #now copy state of random num generators\n",
    "f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23715077], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model: \n",
      "[-0.17144017 -0.12235735 -0.06632164  0.57092876  0.05504196 -0.0648716\n",
      "  0.04003755  0.07577378 -0.03931145 -0.17406691 -0.0935531  -0.2391577\n",
      "  0.61475667  0.21190433  0.14095704 -0.06256582  0.00132707  0.00696094\n",
      "  0.04634598 -0.0507064   0.16730067  0.06043857  0.0847003   0.30302936\n",
      " -0.15396835  0.1418503  -0.0903475   0.05249203 -0.18861605  0.04015244\n",
      "  0.11246356  0.27502742  0.08662615 -0.27868303  0.25967119 -0.00244696\n",
      " -0.12203641 -0.39151491 -0.17180096  0.48442904  0.1062769   0.13057024\n",
      "  0.59204579  0.05835904 -0.19221535  0.06428506  0.1079226  -0.34206992\n",
      "  0.14868259 -0.2548779  -0.1134257   0.10915145 -0.05214226  0.20209501\n",
      " -0.1601143   0.11239614 -0.25225932  0.27854799  0.03342658 -0.01406118\n",
      " -0.09763272 -0.03961872  0.06302567  0.18062666  0.01893438  0.03311746\n",
      " -0.03956982 -0.05927962  0.27202194  0.02021152  0.23111604  0.295915\n",
      " -0.36726737  0.00108652  0.09938558  0.43200296  0.05230785 -0.23255005\n",
      " -0.08899803  0.13055701 -0.02591016  0.28465261  0.19270397  0.19752639\n",
      " -0.19986954  0.1588068  -0.17964626  0.07093789 -0.03291868  0.01109982\n",
      " -0.32782745 -0.04324894  0.23390045 -0.05816624  0.19461259 -0.00380388\n",
      "  0.37115478 -0.03740183 -0.09059225 -0.03728867  0.21764006 -0.26255868\n",
      " -0.33246884  0.0061145   0.10173212 -0.27026145 -0.12863096  0.27407562\n",
      " -0.19906531 -0.12415379 -0.01658349  0.00743925 -0.24295967 -0.48711418\n",
      "  0.22456132  0.26047431  0.18237807  0.28361796 -0.22857363  0.0830562\n",
      "  0.09286912  0.10344255  0.27167514 -0.03666541  0.1151299  -0.10212774\n",
      " -0.5110595   0.22741091  0.2884225   0.33558591 -0.07174499 -0.04520365\n",
      " -0.05126466  0.28329155 -0.18613292  0.28690587  0.17684887 -0.18950737\n",
      "  0.11932472 -0.45940025 -0.09517707 -0.04720154 -0.34602146 -0.16189807\n",
      " -0.36914153  0.29427623 -0.20737546 -0.09933573 -0.13641993  0.2201921\n",
      " -0.20848898  0.192674   -0.10856227 -0.00264306  0.06405778 -0.12947986\n",
      "  0.14804137  0.10622782 -0.02969941  0.50889806 -0.32065671  0.06735543\n",
      " -0.2182661   0.10518995 -0.23444335  0.37520447 -0.07786485  0.11969244\n",
      " -0.14497871 -0.222419   -0.00174338 -0.23062518  0.43396723  0.15450665\n",
      "  0.21538153 -0.01290154  0.13099059  0.15346424  0.2939551   0.13055656\n",
      " -0.29672259 -0.13665866  0.1022864   0.15285776 -0.1791737   0.04503241\n",
      " -0.02325922  0.10163277  0.08069894  0.02952869 -0.14057989 -0.12252935\n",
      " -0.15741613 -0.35789446  0.01240616  0.20380545 -0.28716834  0.27620869\n",
      " -0.05013107  0.26955665  0.24738119 -0.33426646 -0.12723313  0.10833828\n",
      "  0.11506739 -0.3917727  -0.11184405 -0.43766526  0.02872212 -0.01357583\n",
      " -0.24888425 -0.24275627 -0.39328509 -0.12972269  0.10562971  0.12762367\n",
      " -0.19657353  0.3695218   0.4783185  -0.49823458 -0.14240635 -0.25421151\n",
      "  0.10455885  0.0884447   0.27285592 -0.38382362 -0.1011853   0.22585305\n",
      "  0.30256949 -0.02300392  0.17948622  0.07753667 -0.17549999 -0.31740324\n",
      "  0.02956899 -0.2651424   0.33863039  0.02867578  0.10636172  0.21821185\n",
      " -0.14365281  0.37448291  0.14812278 -0.22965507 -0.15662702  0.0310699\n",
      " -0.34585842 -0.15444248 -0.15313827  0.38403718  0.09033972 -0.18196546\n",
      "  0.26642376  0.43609774  0.18160153  0.17428516 -0.04619031 -0.03102002\n",
      " -0.08850594  0.08479988  0.27200783 -0.37483997 -0.25059728 -0.10597087\n",
      " -0.0203212   0.01381195  0.13101073  0.1404788   0.21687179  0.02765807\n",
      " -0.26503402  0.05575951  0.4743041   0.18133048  0.00958793 -0.34776988\n",
      "  0.25132634  0.04084779  0.27879455 -0.14667158 -0.10524345 -0.11805375\n",
      "  0.04729291 -0.10951734 -0.0071645  -0.2804305   0.1557522  -0.15610812\n",
      "  0.01135058 -0.08895759  0.12333472 -0.00964228  0.1516736   0.03622698\n",
      " -0.13887705  0.17005853  0.07518624  0.05284679  0.14354443  0.07573459\n",
      " -0.0851854  -0.09155121  0.09382864  0.43452564  0.43742027 -0.19676231\n",
      " -0.07759479  0.06753921  0.05388244  0.14429102  0.04613862  0.06370052\n",
      "  0.06828041  0.17403725  0.08853258 -0.39752663 -0.12215048  0.02620116\n",
      "  0.10230762 -0.14042724 -0.15810324 -0.10546645  0.25594987 -0.10622566\n",
      "  0.1453016   0.0337953  -0.04914888  0.00947513 -0.50853196  0.40687942\n",
      " -0.14817572 -0.09166657  0.37176308  0.17766982 -0.12935126  0.13294164\n",
      " -0.04401024 -0.2325082  -0.07693776  0.4446223   0.07616    -0.00921084\n",
      "  0.23434785 -0.35373846 -0.17457406 -0.00750453 -0.07722958 -0.38350446\n",
      "  0.11084615 -0.32897623 -0.18194006  0.09704072  0.08025149  0.4173788\n",
      "  0.01953462 -0.31159366  0.1022443   0.39451586  0.12322978 -0.09183701\n",
      " -0.43790661 -0.16696601 -0.13492509 -0.00396586  0.08604703  0.18784061\n",
      " -0.01728123  0.02512928 -0.13131292 -0.12988474 -0.23413843  0.07776618\n",
      " -0.23331343 -0.02539341 -0.3040392  -0.17105914 -0.11116101 -0.12037494\n",
      "  0.0203902   0.06232649  0.02864317  0.23939692  0.05312295  0.08025694\n",
      "  0.15460731 -0.33523712  0.34239995 -0.0940993   0.0808435   0.20276303\n",
      " -0.10025203  0.23403872 -0.08038825  0.08187207  0.10649232  0.08068993\n",
      "  0.14419603 -0.14288326 -0.2495206  -0.37353316 -0.36790525 -0.00989821\n",
      "  0.13101616 -0.29399772 -0.81323364 -0.04998989 -0.06241154 -0.00125062\n",
      "  0.24050257 -0.15173436  0.33816568 -0.16803939  0.32121504 -0.65813145\n",
      "  0.12497709 -0.27255357 -0.31559525 -0.11225425  0.26555855 -0.15138483\n",
      "  0.18382587 -0.11409124  0.24347265 -0.05726191  0.35650678  0.07288514\n",
      "  0.1636909  -0.2110778   0.05570622 -0.23680303 -0.07732531  0.12492378\n",
      " -0.06415659  0.10260317  0.15973212 -0.24241384 -0.14068044  0.07555503\n",
      " -0.15892067 -0.36425544 -0.0368957   0.3547533  -0.13831345 -0.04567232\n",
      "  0.02960284  0.15387254 -0.2298175  -0.30638136  0.3335702  -0.27186162\n",
      "  0.33859247 -0.09146462 -0.35459765 -0.00714232  0.09691456 -0.33827007\n",
      "  0.09065995 -0.23905385  0.16806722  0.05288889 -0.28249023 -0.15170067\n",
      " -0.20002213  0.00446964  0.25626937  0.10955771  0.00134068 -0.55765185\n",
      " -0.04223429  0.13930329 -0.1574516  -0.07814202 -0.0977494   0.17534901\n",
      "  0.27145575  0.16644249 -0.02850639 -0.02522375  0.15976568  0.0565859\n",
      "  0.04118442  0.13166905  0.03719014  0.19613117  0.23671075 -0.27005708\n",
      "  0.20189093 -0.01356736 -0.06320842 -0.33589482  0.28980372  0.04026171\n",
      " -0.04320061 -0.00487747  0.13729761 -0.126959   -0.24845399  0.21466847\n",
      "  0.03505639 -0.17922161  0.38063447 -0.07843711  0.2558552  -0.37631022\n",
      " -0.07818024  0.26554541  0.05038345 -0.01339327 -0.15970665  0.34495712\n",
      " -0.17375067  0.18982899  0.06657057  0.20677318 -0.09878871  0.17430242\n",
      "  0.06071673  0.07641645  0.0587797   0.01061645  0.15507623  0.38104075\n",
      " -0.0566522  -0.14806028 -0.08295149  0.10656224  0.05844878 -0.13978535\n",
      "  0.04750745 -0.04779373 -0.11555419  0.26050514  0.03251515 -0.11392161\n",
      "  0.00635854  0.35638997  0.39642689  0.07781323 -0.18914281  0.01699833\n",
      " -0.06110172  0.11206668  0.1063349   0.30837582 -0.17913442  0.08213258\n",
      "  0.54748588  0.07308964 -0.20031163 -0.35509061 -0.22440822 -0.15227784\n",
      " -0.00414686 -0.45563184  0.25296993  0.02534781 -0.33762211 -0.05822797\n",
      "  0.12103328  0.23159031  0.27586228 -0.19983829  0.19411803  0.23032189\n",
      "  0.01677135 -0.17256831 -0.16049474  0.43875474 -0.04424479  0.29678451\n",
      " -0.03823482  0.19873143  0.2455651  -0.08832622  0.19700081 -0.12183304\n",
      "  0.17411278  0.09443122  0.13967412 -0.36212807 -0.14343874  0.10294713\n",
      "  0.03532283  0.18919431  0.04598559 -0.50990607 -0.19378148 -0.03327077\n",
      "  0.05361211 -0.2942475  -0.22898009 -0.23308395  0.02837384  0.105933\n",
      "  0.00190163 -0.35479453  0.00772629  0.17149215  0.18262461  0.00932675\n",
      " -0.09618415 -0.42015441 -0.06020525 -0.08827406 -0.0699256  -0.12608877\n",
      "  0.11320587 -0.11214495  0.4647422   0.21271879  0.00379067  0.57650182\n",
      "  0.16895955  0.08380862 -0.01113461  0.16012867  0.20600489  0.03802668\n",
      "  0.45774486  0.1627758  -0.18657258  0.07900241 -0.12851706 -0.17376936\n",
      "  0.04364737  0.18323098  0.40395869  0.25945406 -0.12995768 -0.14817735\n",
      "  0.4077975   0.26145974  0.27269103  0.13969918 -0.65527558 -0.1742539\n",
      " -0.12271729  0.08272351  0.03014168 -0.0277275  -0.13101584 -0.36357081\n",
      " -0.07226425  0.00373824  0.00115547  0.16170503  0.06923539 -0.1249021\n",
      " -0.35695989  0.17557232  0.21182476 -0.03129814  0.1735847  -0.22308466\n",
      " -0.05269849  0.00597796  0.10105367 -0.06682018  0.02333266  0.12238944\n",
      "  0.33224146  0.28970446 -0.06945221  0.11887785  0.00998772 -0.09681385\n",
      " -0.20099186 -0.08628582  0.09959786 -0.14996272  0.03635806 -0.06480054\n",
      "  0.06843161  0.06095519  0.28542795 -0.10953353 -0.05688246 -0.21385918\n",
      " -0.145656   -0.0837724  -0.28370238 -0.10856248  0.12860319 -0.53075582\n",
      "  0.39261914  0.19749633  0.52124683  0.05721783  0.22977896  0.12001901\n",
      " -0.017499    0.37227749 -0.34519248  0.43777165 -0.13673696 -0.16572833\n",
      " -0.14615387  0.10683084 -0.25013682  0.00179261  0.15095157  0.0059149\n",
      "  0.08249648 -0.42522287  0.22431679 -0.10188704 -0.10024432 -0.02752668\n",
      "  0.36197286  0.26519203  0.13825571 -0.00915118 -0.05932252  0.09510455\n",
      " -0.21108912  0.42508057 -0.309059   -0.18371158  0.14077414  0.24188557\n",
      "  0.04314182  0.15083249 -0.06222814  0.2254018   0.29244309 -0.1235622\n",
      " -0.01569306  0.15424561  0.20866096  0.22557257 -0.09350798 -0.31691499\n",
      "  0.32225031  0.05133894  0.19207055 -0.04383599  0.18206179 -0.2745033\n",
      "  0.24291802 -0.01154396  0.02092017  0.05981602 -0.02211639  0.10864078\n",
      " -0.01535872  0.14075462 -0.23735151  0.2044786   0.09243028 -0.01576087\n",
      "  0.01334963 -0.1306679   0.12411448 -0.05308799 -0.2735229  -0.16402868\n",
      "  0.18351215  0.02063986  0.10826723  0.30835103 -0.41263056 -0.25144083\n",
      "  0.21281755 -0.41987603  0.10573003  0.00148462 -0.31859841  0.11138801\n",
      " -0.05328319  0.10482034  0.14700186  0.09264509  0.03364632  0.03500276\n",
      "  0.20474528 -0.13101445 -0.16665571  0.11612588  0.41372799  0.26883776\n",
      " -0.4481354   0.16746361  0.197034   -0.16852902]\n",
      "0.346833411237\n",
      "Target values for D: \n",
      "[1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 1 0 0 0 1 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 0\n",
      " 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1\n",
      " 1 1 1 1 0 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1\n",
      " 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 1\n",
      " 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 0 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 0 1 0]\n",
      "prediction on D: \n",
      "[ True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True False  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      " False  True  True  True False  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "rng = numpy.random\n",
    "\n",
    "N = 400\n",
    "feats = 784\n",
    "\n",
    "#generate dataset D = (input_values,target_class)\n",
    "D = (rng.rand(N,feats), rng.randint(size=N,low=0,high=2))\n",
    "training_steps = 10000\n",
    "\n",
    "x = T.dmatrix('x')\n",
    "y = T.dvector('y')\n",
    "\n",
    "#initialize weight matrix w randomly, then bias vector b\n",
    "w = shared(rng.randn(feats),name=\"w\")\n",
    "b = shared(0.,name=\"b\")\n",
    "\n",
    "#print(\"Initial model: \")\n",
    "#print(w.get_value())\n",
    "#print(b.get_value())\n",
    "\n",
    "#construct Theano expression graph\n",
    "p_1 = 1 / (1 + T.exp(-T.dot(x,w) - b)) #prob that target = 1\n",
    "prediction = p_1 > 0.5\n",
    "xent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) #the crossentropy cost function!\n",
    "cost = xent.mean() + 0.01 *  (w**2).sum() #cost to minimize\n",
    "gw,gb = T.grad(cost,[w,b])\n",
    "\n",
    "\n",
    "#Compile!\n",
    "train = function(\n",
    "            inputs=[x,y],\n",
    "            outputs=[prediction,xent],\n",
    "            updates=((w,w-0.1*gw),(b,b-0.1*gb))) #update wt, bias vectors w/ lr = 0.1\n",
    "predict = function(inputs=[x],outputs=prediction)\n",
    "\n",
    "#Train\n",
    "for i in range(training_steps):\n",
    "    pred,err = train(D[0],D[1])\n",
    "    \n",
    "    \n",
    "print(\"Final model: \")\n",
    "print(w.get_value())\n",
    "print(b.get_value())\n",
    "print(\"Target values for D: \")\n",
    "print(D[1])\n",
    "print(\"prediction on D: \")\n",
    "print(predict(D[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivatives/Gradients in Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'((fill((x ** TensorConstant{2}), TensorConstant{1.0}) * TensorConstant{2}) * (x ** (TensorConstant{2} - TensorConstant{1})))'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dscalar('x')\n",
    "y = x**2\n",
    "gy = T.grad(y,x)\n",
    "pp(gy) #print grad prior to optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = function([x],gy)\n",
    "f(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.allclose(f(94.2),188.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient of the logistic functinion sigmoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25      ,  0.19661193],\n",
       "       [ 0.19661193,  0.10499359]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = T.dmatrix('x')\n",
    "s = T.sum(1 / (1 + T.exp(-x)))\n",
    "gs = T.grad(s,x)\n",
    "dlogistic = function([x],gs)\n",
    "dlogistic([[0,1],[-1,-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll compute the Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.,  0.],\n",
       "       [ 0.,  8.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano import scan\n",
    "x = T.dvector('x')\n",
    "y = x**2\n",
    "J,updates = scan(lambda i,y,x: T.grad(y[i],x), sequences=T.arange(y.shape[0]), non_sequences=[y,x])\n",
    "f = function([x],J,updates=updates)\n",
    "f([4,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Bad input argument to theano function with name \"<ipython-input-65-62025576ae8d>:12\" at index 2 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-65-62025576ae8d>\", line 6, in <module>\n    x,y = T.matrices('x', 'y')\nTensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\". Value: \"array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       ..., \n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.]])\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-62025576ae8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mf_switch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_mat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_mat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time spent evaluating both values %f sec'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    812\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m'\"function\". Value: \"%s\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                             % (self, data.dtype, self.dtype, repr(data)))\n\u001b[0;32m--> 140\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 elif (allow_downcast is None and\n\u001b[1;32m    142\u001b[0m                         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Bad input argument to theano function with name \"<ipython-input-65-62025576ae8d>:12\" at index 2 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/dbashir/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-65-62025576ae8d>\", line 6, in <module>\n    x,y = T.matrices('x', 'y')\nTensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\". Value: \"array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       ..., \n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n       [ 1.,  1.,  1., ...,  1.,  1.,  1.]])\""
     ]
    }
   ],
   "source": [
    "from theano import tensor as T\n",
    "from theano.ifelse import ifelse\n",
    "import theano, time, numpy\n",
    "\n",
    "a,b = T.scalars('a', 'b')\n",
    "x,y = T.matrices('x', 'y')\n",
    "\n",
    "z_switch = T.switch(T.lt(a, b), T.mean(x), T.mean(y))\n",
    "z_lazy = ifelse(T.lt(a, b), T.mean(x), T.mean(y))\n",
    "\n",
    "f_switch = theano.function([a, b, x, y], z_switch,\n",
    "                           mode=theano.Mode(linker='vm'))\n",
    "f_lazyifelse = theano.function([a, b, x, y], z_lazy,\n",
    "                               mode=theano.Mode(linker='vm'))\n",
    "\n",
    "val1 = 0.\n",
    "val2 = 1.\n",
    "big_mat1 = numpy.ones((10000, 1000))\n",
    "big_mat2 = numpy.ones((10000, 1000))\n",
    "\n",
    "n_times = 10\n",
    "\n",
    "tic = time.clock()\n",
    "for i in range(n_times):\n",
    "    f_switch(val1, val2, big_mat1, big_mat2)\n",
    "print('time spent evaluating both values %f sec' % (time.clock() - tic))\n",
    "\n",
    "tic = time.clock()\n",
    "for i in range(n_times):\n",
    "    f_lazyifelse(val1, val2, big_mat1, big_mat2)\n",
    "print('time spent evaluating one value %f sec' % (time.clock() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loops/Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96402758  0.99505478]\n",
      " [ 0.96402758  0.99505478]]\n",
      "[[ 0.96402758  0.99505478]\n",
      " [ 0.96402758  0.99505478]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# defining the tensor variables\n",
    "X = T.matrix(\"X\")\n",
    "W = T.matrix(\"W\")\n",
    "b_sym = T.vector(\"b_sym\")\n",
    "\n",
    "results,updates = theano.scan(lambda v: T.tanh(T.dot(v,W) + b_sym), sequences=X)\n",
    "compute_elementwise = theano.function(inputs=[X, W, b_sym], outputs=results)\n",
    "\n",
    "#test values\n",
    "x = np.eye(2, dtype = theano.config.floatX)\n",
    "w = np.ones((2,2), dtype = theano.config.floatX)\n",
    "b = np.ones((2), dtype = theano.config.floatX)\n",
    "b[1] = 2\n",
    "\n",
    "print(compute_elementwise(x,w,b))\n",
    "\n",
    "#compare w numpy\n",
    "print(np.tanh(x.dot(w) + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999994  0.99999994]\n",
      " [ 0.99998772  0.99998772]\n",
      " [ 0.99998772  0.99998772]\n",
      " [ 0.99998772  0.99998772]\n",
      " [ 1.          1.        ]]\n",
      "[[ 0.99999994  0.99999994]\n",
      " [ 0.99998772  0.99998772]\n",
      " [ 0.99998772  0.99998772]\n",
      " [ 0.99998772  0.99998772]\n",
      " [ 1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# define tensor variables\n",
    "X = T.vector(\"X\")\n",
    "W = T.matrix(\"W\")\n",
    "b_sym = T.vector(\"b_sym\")\n",
    "U = T.matrix(\"U\")\n",
    "Y = T.matrix(\"Y\")\n",
    "V = T.matrix(\"V\")\n",
    "P = T.matrix(\"P\")\n",
    "\n",
    "results,updates = theano.scan(lambda y,p,x_tm1: T.tanh(T.dot(x_tm1,W) + T.dot(y,U) + T.dot(p,V)),\n",
    "                             sequences = [Y, P[::-1]], outputs_info=[X])\n",
    "compute_seq = theano.function(inputs=[X,W,Y,U,P,V], outputs=results)\n",
    "\n",
    "#test values\n",
    "x = np.zeros((2), dtype=theano.config.floatX)\n",
    "x[1] = 1\n",
    "w = np.ones((2,2), dtype=theano.config.floatX)\n",
    "y = np.ones((5,2), dtype=theano.config.floatX)\n",
    "y[0, :] = 3\n",
    "u = np.ones((2,2), dtype=theano.config.floatX)\n",
    "p = np.ones((5,2), dtype=theano.config.floatX)\n",
    "p[0, :] = 3\n",
    "v = np.ones((2, 2), dtype=theano.config.floatX)\n",
    "\n",
    "print(compute_seq(x, w, y, u, p, v))\n",
    "\n",
    "# comparison with numpy\n",
    "x_res = np.zeros((5, 2), dtype=theano.config.floatX)\n",
    "x_res[0] = np.tanh(x.dot(w) + y[0].dot(u) + p[4].dot(v))\n",
    "for i in range(1, 5):\n",
    "    x_res[i] = np.tanh(x_res[i - 1].dot(w) + y[i].dot(u) + p[4-i].dot(v))\n",
    "print(x_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
