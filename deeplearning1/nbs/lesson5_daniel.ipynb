{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5103 on context None\n",
      "Preallocating 10867/11439 Mb (0.950000) on cuda\n",
      "Mapped name None to device cuda: Tesla K40c (0000:81:00.0)\n"
     ]
    },
    {
     "ename": "SkipTest",
     "evalue": "You are importing theano.sandbox.cuda. This is the old GPU back-end and is removed from Theano. Use Theano 0.9 to use it. Even better, transition to the new GPU back-end! See https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSkipTest\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-72d9ba0ec1eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msandbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# the folder will be skipped by nosetests without failing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m raise SkipTest(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m\"You are importing theano.sandbox.cuda. This is the old GPU back-end and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"is removed from Theano. Use Theano 0.9 to use it. Even better, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"transition to the new GPU back-end! See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSkipTest\u001b[0m: You are importing theano.sandbox.cuda. This is the old GPU back-end and is removed from Theano. Use Theano 0.9 to use it. Even better, transition to the new GPU back-end! See https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'data/imdb/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "idx = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'a', 'of', 'to', 'is', 'br', 'in', 'it', 'i']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_arr = sorted(idx,key=idx.get)\n",
    "idx_arr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {v: k for k,v in idx.iteritems()} #iteritems returns iterator over dict's key/value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)\n",
    "#print(x_train[0][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23022, 309, 6, 3, 1069, 209, 9, 2175, 30, 1, 169, 55, 14, 46, 82, 5869, 41, 393, 110, 138, 14, 5359, 58, 4477, 150, 8, 1, 5032, 5948, 482, 69, 5, 261, 12, 23022, 73935, 2003, 6, 73, 2436, 5, 632, 71, 6, 5359, 1, 25279, 5, 2004, 10471, 1, 5941, 1534, 34, 67, 64, 205, 140, 65, 1232, 63526, 21145, 1, 49265, 4, 1, 223, 901, 29, 3024, 69, 4, 1, 5863, 10, 694, 2, 65, 1534, 51, 10, 216, 1, 387, 8, 60, 3, 1472, 3724, 802, 5, 3521, 177, 1, 393, 10, 1238, 14030, 30, 309, 3, 353, 344, 2989, 143, 130, 5, 7804, 28, 4, 126, 5359, 1472, 2375, 5, 23022, 309, 10, 532, 12, 108, 1470, 4, 58, 556, 101, 12, 23022, 309, 6, 227, 4187, 48, 3, 2237, 12, 9, 215'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(map(str, x_train[0])) #join word IDs in x_train[0] with commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[23022] #looks up word ID in dict and gives corresponding value k in word index dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(idx2word[o] for o in x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 is positive labels, 0 are negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train[:10] #this came from code copied from keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#limit the size of vocab to 5000\n",
    "vocab_size = 5000\n",
    "\n",
    "trn = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_train]\n",
    "test = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2493, 10, 237.71364)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = np.array(map(len,trn)) #create array of lengths of sentences in words\n",
    "(lens.max(),lens.min(),lens.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pad w/ 0s or truncate to make all the same length\n",
    "seq_len = 500\n",
    "\n",
    "#use keras pad_sequences\n",
    "trn = sequence.pad_sequences(trn, maxlen=seq_len,value=0)\n",
    "test = sequence.pad_sequences(test,maxlen=seq_len,value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single hidden layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 32, input_length=seq_len),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])\n",
    "#in embedding layer 32 is its output dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 500, 32)       160000      embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 16000)         0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           1600100     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             101         dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,760,201\n",
      "Trainable params: 1,760,201\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 1s - loss: 0.4633 - acc: 0.7530 - val_loss: 0.2903 - val_acc: 0.8755\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 1s - loss: 0.1978 - acc: 0.9265 - val_loss: 0.3002 - val_acc: 0.8736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93110009d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Conv Layer, max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1 = Sequential([\n",
    "    Embedding(vocab_size,32,input_length=seq_len,dropout=0.2),\n",
    "    Dropout(0.2),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.5287 - acc: 0.7035 - val_loss: 0.3036 - val_acc: 0.8762\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.2980 - acc: 0.8815 - val_loss: 0.2757 - val_acc: 0.8865\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.2626 - acc: 0.8968 - val_loss: 0.2599 - val_acc: 0.8940\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.2398 - acc: 0.9072 - val_loss: 0.2735 - val_acc: 0.8850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f930376f750>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=4,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.save_weights(model_path + 'conv1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.load_weights(model_path + 'conv1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_glove_dataset(dataset):\n",
    "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
    "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
    "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
    "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
    "    glove_path = os.path.abspath('data/glove/results')\n",
    "    %mkdir -p $glove_path\n",
    "    return get_file(dataset,\n",
    "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
    "                    cache_subdir=glove_path,\n",
    "                    md5_hash=md5sums.get(dataset, None),\n",
    "                    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "            pickle.load(open(loc+'_words.pkl','rb')),\n",
    "            pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untaring file...\n"
     ]
    }
   ],
   "source": [
    "vecs,words,wordidx = load_vectors(get_glove_dataset('6B.50d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size,n_fact))\n",
    "    \n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "            src_idx = wordidx[word]\n",
    "            emb[i] = vecs[src_idx]\n",
    "        else:\n",
    "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "            \n",
    "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,\n",
    "             weights=[emb],trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 5s - loss: 0.5928 - acc: 0.6755 - val_loss: 0.4977 - val_acc: 0.7888\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 5s - loss: 0.4962 - acc: 0.7677 - val_loss: 0.4408 - val_acc: 0.8086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92e6c3d590>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 5s - loss: 0.4743 - acc: 0.7800 - val_loss: 0.4220 - val_acc: 0.8173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9302c649d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=1,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(model_path+'glove50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-size CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_in = Input((vocab_size,50))\n",
    "convs=[ ]\n",
    "for fsz in range(3,6):\n",
    "    x = Convolution1D(64,fsz,border_mode='same',activation='relu')(graph_in)\n",
    "    x=MaxPooling1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    convs.append(x)\n",
    "out = Merge(mode=\"concat\")(convs)\n",
    "graph = Model(graph_in,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential ([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,weights=[emb]),\n",
    "    Dropout(0.2),\n",
    "    graph,\n",
    "    Dropout(0.5),\n",
    "    Dense(100,activation=\"relu\"),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.4922 - acc: 0.7460 - val_loss: 0.3446 - val_acc: 0.8453\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.3153 - acc: 0.8713 - val_loss: 0.2588 - val_acc: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92e3538090>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2821 - acc: 0.8868 - val_loss: 0.2619 - val_acc: 0.8956\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2621 - acc: 0.8953 - val_loss: 0.2523 - val_acc: 0.8979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92e5fbda90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My own CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll use the pre-trained weights here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,\n",
    "             weights=[emb],trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(32,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 9s - loss: 0.6021 - acc: 0.6636 - val_loss: 0.5356 - val_acc: 0.7488\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 9s - loss: 0.4895 - acc: 0.7690 - val_loss: 0.4790 - val_acc: 0.8149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92ddd99d90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 9s - loss: 0.4668 - acc: 0.7838 - val_loss: 0.4966 - val_acc: 0.7844\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 9s - loss: 0.4520 - acc: 0.7905 - val_loss: 0.4271 - val_acc: 0.8276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92e03bfcd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,\n",
    "             weights=[emb],trainable=False),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(32,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 7s - loss: 0.6263 - acc: 0.6241 - val_loss: 0.5183 - val_acc: 0.7902\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 7s - loss: 0.4965 - acc: 0.7677 - val_loss: 0.4788 - val_acc: 0.8051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92db80cb90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 7s - loss: 0.4704 - acc: 0.7826 - val_loss: 0.4482 - val_acc: 0.8048\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 7s - loss: 0.4576 - acc: 0.7887 - val_loss: 0.4231 - val_acc: 0.8354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92ddfe51d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,\n",
    "             weights=[emb],trainable=True),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(32,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 11s - loss: 0.5592 - acc: 0.6663 - val_loss: 0.4817 - val_acc: 0.8406\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 11s - loss: 0.3274 - acc: 0.8658 - val_loss: 0.3244 - val_acc: 0.8970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92d968dcd0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 11s - loss: 0.2485 - acc: 0.8991 - val_loss: 0.3436 - val_acc: 0.8559\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 11s - loss: 0.2418 - acc: 0.9036 - val_loss: 0.2725 - val_acc: 0.9017\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 11s - loss: 0.2296 - acc: 0.9109 - val_loss: 0.2765 - val_acc: 0.9019\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 11s - loss: 0.2238 - acc: 0.9111 - val_loss: 0.2930 - val_acc: 0.8928\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 11s - loss: 0.2179 - acc: 0.9149 - val_loss: 0.2607 - val_acc: 0.9027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92d823a410>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=5,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 11s - loss: 0.1865 - acc: 0.9254 - val_loss: 0.2512 - val_acc: 0.9035\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 11s - loss: 0.1820 - acc: 0.9298 - val_loss: 0.2449 - val_acc: 0.9044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92d7bd2410>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 11s - loss: 0.1788 - acc: 0.9319 - val_loss: 0.2532 - val_acc: 0.9012\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 11s - loss: 0.1708 - acc: 0.9350 - val_loss: 0.2474 - val_acc: 0.9028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9374508b90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Nadam\n",
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 9s - loss: 0.1770 - acc: 0.9316 - val_loss: 0.2488 - val_acc: 0.9016\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 9s - loss: 0.1760 - acc: 0.9324 - val_loss: 0.2718 - val_acc: 0.8885\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 9s - loss: 0.1688 - acc: 0.9348 - val_loss: 0.2492 - val_acc: 0.9026\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 9s - loss: 0.1693 - acc: 0.9357 - val_loss: 0.2834 - val_acc: 0.8820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92d74e6810>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=4,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can we not overfit pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,\n",
    "             weights=[emb],trainable=True),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.4898 - acc: 0.7376 - val_loss: 0.3099 - val_acc: 0.8863\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.3062 - acc: 0.8768 - val_loss: 0.3554 - val_acc: 0.8439\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.2749 - acc: 0.8894 - val_loss: 0.2672 - val_acc: 0.8978\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.2581 - acc: 0.8983 - val_loss: 0.2917 - val_acc: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92d39e0990>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=4,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ditch the pretrained weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid', W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.6955 - acc: 0.4950 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.6932 - acc: 0.4957 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.6932 - acc: 0.5026 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.6932 - acc: 0.4963 - val_loss: 0.6932 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92da0d1410>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=4,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### they back but w reg this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,\n",
    "             weights=[emb],trainable=True),\n",
    "    Dropout(0.25),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.35),\n",
    "    MaxPooling1D(),\n",
    "    Convolution1D(64,5,border_mode='same',activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation='sigmoid', W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.4590 - acc: 0.7740 - val_loss: 0.3399 - val_acc: 0.8926\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.3064 - acc: 0.8811 - val_loss: 0.3116 - val_acc: 0.8973\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.2718 - acc: 0.8901 - val_loss: 0.2779 - val_acc: 0.9027\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 10s - loss: 0.2539 - acc: 0.9021 - val_loss: 0.2864 - val_acc: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92d10cbad0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=4,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got em but sort of overfit on the last epoch maybe do less nxt time that was p good tho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### that multilayer thing WITH REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_in = Input((vocab_size,50))\n",
    "convs=[ ]\n",
    "for fsz in range(3,6):\n",
    "    x = Convolution1D(64,fsz,border_mode='same',activation='relu')(graph_in)\n",
    "    x=MaxPooling1D()(x)\n",
    "    x = Flatten()(x)\n",
    "    convs.append(x)\n",
    "out = Merge(mode=\"concat\")(convs)\n",
    "graph = Model(graph_in,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential ([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,weights=[emb]),\n",
    "    Dropout(0.2),\n",
    "    graph,\n",
    "    Dropout(0.5),\n",
    "    Dense(100,activation=\"relu\"),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation=\"sigmoid\", W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The model needs to be compiled before being used.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-14fd97901cb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dbashir/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \"\"\"\n\u001b[1;32m    649\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             raise RuntimeError('The model needs to be compiled '\n\u001b[0m\u001b[1;32m    651\u001b[0m                                'before being used.')\n\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'show_accuracy'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The model needs to be compiled before being used."
     ]
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2858 - acc: 0.8884 - val_loss: 0.2637 - val_acc: 0.8941\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2621 - acc: 0.8984 - val_loss: 0.2599 - val_acc: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92cf56ab50>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what if we do softmax instead?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential ([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,weights=[emb]),\n",
    "    Dropout(0.2),\n",
    "    graph,\n",
    "    Dropout(0.5),\n",
    "    Dense(100,activation=\"relu\"),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation=\"softmax\", W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 7.9751 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92cbe75f10>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok that was terrible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential ([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,weights=[emb]),\n",
    "    Dropout(0.2),\n",
    "    graph,\n",
    "    Dropout(0.4),\n",
    "    Dense(100,activation=\"relu\"),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation=\"sigmoid\", W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.4014 - acc: 0.8279 - val_loss: 0.3219 - val_acc: 0.8706\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2974 - acc: 0.8813 - val_loss: 0.2753 - val_acc: 0.8895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92c67d7950>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2680 - acc: 0.8926 - val_loss: 0.2601 - val_acc: 0.8960\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2480 - acc: 0.9006 - val_loss: 0.2555 - val_acc: 0.8992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92d0e18190>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wat if we do more dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential ([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,weights=[emb]),\n",
    "    Dropout(0.2),\n",
    "    graph,\n",
    "    Dropout(0.5),\n",
    "    Dense(100,activation=\"relu\"),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation=\"sigmoid\", W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.3963 - acc: 0.8267 - val_loss: 0.2992 - val_acc: 0.8816\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2961 - acc: 0.8817 - val_loss: 0.2673 - val_acc: 0.9002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92c38a7e10>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2682 - acc: 0.8926 - val_loss: 0.2655 - val_acc: 0.9014\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2475 - acc: 0.9015 - val_loss: 0.2581 - val_acc: 0.8984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92c48b7b50>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE BEAT HIM but still overfit @ the end saddddddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential ([\n",
    "    Embedding(vocab_size,50,input_length=seq_len,dropout=0.2,weights=[emb]),\n",
    "    Dropout(0.25),\n",
    "    graph,\n",
    "    Dropout(0.5),\n",
    "    Dense(100,activation=\"relu\"),\n",
    "    Dropout(0.7),\n",
    "    Dense(1,activation=\"sigmoid\", W_regularizer=l2(0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Nadam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.3986 - acc: 0.8272 - val_loss: 0.2938 - val_acc: 0.8948\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.3014 - acc: 0.8759 - val_loss: 0.2701 - val_acc: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92c8d22950>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2704 - acc: 0.8922 - val_loss: 0.2744 - val_acc: 0.8918\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 18s - loss: 0.2503 - acc: 0.9023 - val_loss: 0.2672 - val_acc: 0.8982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92c1957610>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trn,labels_train,validation_data=(test,labels_test),nb_epoch=2,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
