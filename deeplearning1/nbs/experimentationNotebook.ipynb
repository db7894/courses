{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal/point of this notebook is to experiment with different architectures for a CNN that does image classification (I will likely use cats/dogs for ease). I will use both my own and those inspired by other sources. The hope is that I will:\n",
    "1. Be able to produce classifiers that achieve >90% accuracy\n",
    "2. Understand what exactly goes into a good classifier, and how/why the structure makes it so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T00:56:22.513432Z",
     "start_time": "2018-02-09T00:56:18.789288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5103 on context None\n",
      "Preallocating 10867/11439 Mb (0.950000) on cuda\n",
      "Mapped name None to device cuda: Tesla K40c (0000:81:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division,print_function\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "from matplotlib import pyplot as plt\n",
    "import utils; reload(utils)\n",
    "from utils import plots, get_batches, plot_confusion_matrix, get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T00:56:22.534831Z",
     "start_time": "2018-02-09T00:56:22.519603Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import relevant keras stuff\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T00:56:22.544585Z",
     "start_time": "2018-02-09T00:56:22.539702Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T00:56:22.554894Z",
     "start_time": "2018-02-09T00:56:22.549633Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/dogscats/\"\n",
    "model_path = \"data/dogscats/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T00:56:23.484696Z",
     "start_time": "2018-02-09T00:56:22.558372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = get_batches(path+'train',batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid',batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:14.118831Z",
     "start_time": "2018-02-09T00:56:23.488725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(path+'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:34.358558Z",
     "start_time": "2018-02-09T01:00:14.124872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data = get_data(path+'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:34.371798Z",
     "start_time": "2018-02-09T01:00:34.364527Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:44.626665Z",
     "start_time": "2018-02-09T01:00:34.376151Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array('train_data.bc',train_data)\n",
    "save_array('val_data.bc',val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:58.546633Z",
     "start_time": "2018-02-09T01:00:44.632327Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = load_array('train_data.bc')\n",
    "val_data = load_array('val_data.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:58.556828Z",
     "start_time": "2018-02-09T01:00:58.551775Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(x): return np.array(OneHotEncoder().fit_transform(x.reshape(-1,1)).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OneHot encoding converts an array of labels (numbers 1 through n) to a matrix that has the same number of rows but now n columns. The number k in the original vector is encoded by a 1 in the kth column of our new matrix, while the rest of the row is populated with zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:58.574918Z",
     "start_time": "2018-02-09T01:00:58.561479Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_classes = val_batches.classes\n",
    "train_classes = train_batches.classes\n",
    "val_labels = onehot(val_classes)\n",
    "train_labels = onehot(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:58.590468Z",
     "start_time": "2018-02-09T01:00:58.579090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:58.602368Z",
     "start_time": "2018-02-09T01:00:58.594520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:58.614744Z",
     "start_time": "2018-02-09T01:00:58.606517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:58.626455Z",
     "start_time": "2018-02-09T01:00:58.619190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000, 3, 224, 224)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a basic model that I (randomly) wrote myself--it achieves about a 50% accuracy at best, so not a great classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-09T01:00:59.795057Z",
     "start_time": "2018-02-09T01:00:58.639210Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelOne = Sequential()\n",
    "#input = 224x224 images\n",
    "#first arg is the # of filters, then the size (16 filters, size 3x3 not entered as a tuple)\n",
    "modelOne.add(Convolution2D(64,3,3, activation='relu', input_shape=train_data.shape[1:]))\n",
    "modelOne.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelOne.add(Convolution2D(32,3,3, activation='relu'))\n",
    "modelOne.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelOne.add(Convolution2D(32,1,1, activation='relu'))\n",
    "modelOne.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelOne.add(Convolution2D(16,1,1, activation='relu'))\n",
    "modelOne.add(MaxPooling2D(pool_size=(2,2)))\n",
    "modelOne.add(Flatten()) #flattens 3D shape to 2D for Dense layer\n",
    "#modelOne.add(Dropout(0.25))\n",
    "modelOne.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-09T00:56:19.549Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelOne.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-09T00:56:19.551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23000/23000 [==============================] - 105s - loss: 1.1916 - acc: 0.5418   \n",
      "Epoch 2/2\n",
      "23000/23000 [==============================] - 104s - loss: 0.7031 - acc: 0.5877   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc04b8cf3d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelOne.fit(train_data,train_labels,nb_epoch=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-09T00:56:19.552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 3s     \n"
     ]
    }
   ],
   "source": [
    "score = modelOne.evaluate(val_data,val_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelOne.save('secondTry.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66453420639038085, 0.61399999999999999]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll try to implement a model based on the \"let's keep it simple\" paper by Hasanpour et al. \n",
    "The paper can be found here: https://arxiv.org/ftp/arxiv/papers/1608/1608.06037.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simpleModel = Sequential()\n",
    "\n",
    "simpleModel.add(Convolution2D(64,3,3, activation='relu', input_shape=train_data.shape[1:]))\n",
    "simpleModel.add(Convolution2D(128,3,3,activation='relu'))\n",
    "simpleModel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "simpleModel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "simpleModel.add(Convolution2D(128,3,3, activation='relu'))\n",
    "simpleModel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "simpleModel.add(Convolution2D(128,3,3, activation='relu'))\n",
    "simpleModel.add(Convolution2D(128,3,3, activation='relu'))\n",
    "simpleModel.add(MaxPooling2D(pool_size=(2,2)))\n",
    "simpleModel.add(Convolution2D(128,3,3, activation='relu'))\n",
    "#NOTE: The 11th and 12th layers utilize 1x1 convolutional kernels instead of 3x3.\n",
    "simpleModel.add(Convolution2D(128,1,1, activation='relu'))\n",
    "simpleModel.add(Convolution2D(128,1,1, activation='relu'))\n",
    "simpleModel.add(Convolution2D(128,3,3, activation='relu'))\n",
    "simpleModel.add(Flatten())\n",
    "simpleModel.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simpleModel.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "23000/23000 [==============================] - 549s - loss: 0.6845 - acc: 0.5875   \n",
      "Epoch 2/2\n",
      "23000/23000 [==============================] - 549s - loss: 0.6377 - acc: 0.6287   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc03f3fcbd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleModel.fit(train_data,train_labels,nb_epoch=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simpleModel.save('thirdTry.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below is another network I will attempt (Mek's example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Conv2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-763a6138cca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.add(Conv2D(32, kernel_size=(3, 3),\n\u001b[0m\u001b[1;32m      3\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  input_shape=input_shape))\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Conv2D' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32,3,3,\n",
    "                 activation='relu',\n",
    "                 input_shape=train_data.shape[1:]))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_data,train_labels,nb_epoch=2,batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
